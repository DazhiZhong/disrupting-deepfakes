{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "disrupt-deepfake",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZegFYCrGjJqD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLUkxqVu5DeO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "2dcfb6e1-392d-4381-9f18-a2916269c0a7"
      },
      "source": [
        "!git clone https://github.com/dazhizhong/disrupting-deepfakes.git\n",
        "%cd disrupting-deepfakes\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'disrupting-deepfakes'...\n",
            "remote: Enumerating objects: 94, done.\u001b[K\n",
            "remote: Counting objects: 100% (94/94), done.\u001b[K\n",
            "remote: Compressing objects: 100% (63/63), done.\u001b[K\n",
            "remote: Total 1594 (delta 61), reused 55 (delta 31), pack-reused 1500\u001b[K\n",
            "Receiving objects: 100% (1594/1594), 50.44 MiB | 39.49 MiB/s, done.\n",
            "Resolving deltas: 100% (728/728), done.\n",
            "/content/disrupting-deepfakes\n",
            "cyclegan  ganimation  imgs  pix2pixHD  README.md  stargan\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jX26rESZeLtB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Notif sound\n",
        "from google.colab import output\n",
        "def notif(sound = 0):\n",
        "  if sound ==0:\n",
        "    output.eval_js('new Audio(\"https://notificationsounds.com/message-tones/appointed-529/download/mp3\").play()')\n",
        "  elif sound == 1:\n",
        "    output.eval_js('new Audio(\"https://dazhizhong.github.io/ringleader.webm\").play()')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxMW9GYq5RLb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "33b67f2b-f209-4ad3-eea9-0b1325ecf3d4"
      },
      "source": [
        "%cd stargan"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/disrupting-deepfakes/stargan\n",
            "advertorch\tdefenses     LICENSE\tmodel.py   solver.py\n",
            "attacks.py\tdownload.sh  logger.py\tnoise.py\n",
            "data_loader.py\tjpg\t     main.py\tREADME.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ti6pCM0z5j5J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# no output\n",
        "%%capture\n",
        "%%bash \n",
        "bash download.sh celeba"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7I9Pz5th55y1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# no output\n",
        "%%capture\n",
        "%%bash\n",
        "bash download.sh pretrained-celeba-128x128"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5xR8xZnnMhI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "3ae7c9cd-1b80-4042-bfc1-343ce71a68b6"
      },
      "source": [
        "!git clone https://github.com/DazhiZhong/Pytorch-metrics.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Pytorch-metrics'...\n",
            "remote: Enumerating objects: 28, done.\u001b[K\n",
            "remote: Counting objects: 100% (28/28), done.\u001b[K\n",
            "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
            "remote: Total 28 (delta 9), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (28/28), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIoWMC9fGgKg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv Pytorch-metrics metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5J3YzaKJzlMd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp  metrics/metrics.py metrics.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZT9dcNn7-Sht",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "fa38025f-c56b-4f30-db22-eee630d54a04"
      },
      "source": [
        "gpu = GPUs[0]\n",
        "def printm():\n",
        "  process = psutil.Process(os.getpid())\n",
        "  print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "  print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "\n",
        "printm()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gen RAM Free: 12.8 GB  | Proc size: 190.7 MB\n",
            "GPU RAM Free: 7611MB | Used: 0MB | Util   0% | Total 7611MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAhsL9PD-F-d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "!python main.py --mode test --dataset CelebA --image_size 128 --c_dim 5 --model_save_dir='stargan_celeba_128/models' --result_dir='stargan_celeba_128/results_test' --test_iters 200000 --batch_size 1\n",
        "notif(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcYVL-R5ivWQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob,os\n",
        "for i in glob.glob('stargan_celeba_128/results_test/*images.jpg'):\n",
        "  os.remove(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gbo9FmiICSq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "d14392c9-6ff4-4c00-b9ca-4b28b3241925"
      },
      "source": [
        "!7z a results.7z /content/disrupting-deepfakes/stargan/stargan_celeba_128/results_test "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.00GHz (50653),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive:\n",
            "  0M Scan  /content/disrupting-deepfakes/stargan/stargan_celeba_128/\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1 folder, 10 files, 464962 bytes (455 KiB)\n",
            "\n",
            "Creating archive: nice.7z\n",
            "\n",
            "Items to compress: 11\n",
            "\n",
            "  0%\b\b\b\b    \b\b\b\b\n",
            "Files read from disk: 10\n",
            "Archive size: 436776 bytes (427 KiB)\n",
            "Everything is Ok\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}